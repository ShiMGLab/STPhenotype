# STPhenotype
Integrating spatial gene and morphology with deep learning for phenotypic classification

## Summary
The STPhenotype model mainly includes two parts: image feature extraction and cell phenotype classification. The whole process is shown in Fig. 1. First, take the image blocks of each spot of the H&E stained images and input them into the residual neural network module with spatial attention and channel attention to obtain the vectors generated by the images of each spot. The vectors of all spots are merged as the image feature data matrix, which is fused with the gene counting matrix and manifold aligned to learn the similarity between the two modal data. All the data are input into the classifier, and the learned feature relationship is used as the penalty item, and finally output the prediction type of each spot.

## Requirements
```
[python >=3.7]
[TensorFlow 1.4.0]
[scikit-learn 0.18]
[keras 2.2.4]
[seaborn 0.9.0]
[opencv 4.1.1]
[pandas 0.25.0]
[pillow 6.1.0]
[python-spams 2.6.1]
[staintools 2.1.2]
[Others as specified in the requirements.yml file]
```
##  How to Run
# Feature extraction of H&E stained images using residual network structure
image.py
# Manifold alignment of image data and gene expression data
phase1.py
# Regularization classification by manifold align
class.py

##  Installation


## Example
Check class.py file for an example.

